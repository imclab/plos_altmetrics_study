h1.  Normalization

h2. The need for normalization

If we are going to compare alt-metrics, we have to normalize the data for each alt-metric across time.  There are two ways that **the date of publication impacts the number of alt-metric events** accumulated by an article, as measured at a given point in time:

*  Two articles may receive a different number of events **if they were published at times when the alt-metric had a different level of baseline activity**.  The activity levels of an alt-metric service may vary as a field grows or shrinks or a service becomes more or less popular. 
*  Two articles may also receive a different number of events-to-date **if the articles have had a different amount of time to accumulate events**.  Some metrics, such as citations and bookmarking, might be more sensitive to differing accumulation durations than other metrics.

Given only events-to-date data we can not distinguish these events from each other, but we can normalize for both of them simultaneously.  

h2. Normalization method

To normalize, let's get the mean number of events within a given time window and divide each event size by this "expected" event size to normalize the number of events over time.

Specifically, we choose a window of 
{{ d['sections']['do_normalization_idio.R|idio|rint|pyg']['WINDOW_WIDTH_IN_DAYS'] }}

So for any given event, we normalize its counts using alt-metrics on all articles published half of this width beforehand and half of this width afterwards.

Rather than doing a straight mean across this window, we do a weighted mean that gives most emphasis to points closest in time to the given point.  This is standard signal processing technique.

We use a hamming window, which looks like this:

!file:////Users/hpiwowar/Documents/altmetrics.analysis/inst/doc_src/dexy_artifacts/hamming.png!


h3.  Details

- **use mean or median?**  We should use the mean.  It is a relevant distinction if 60% vs 80% of the articles have zero events:  the medians would be 0 in both cases but the means would differ.
- **transform the event counts before normalization?** No.
- **also normalize variance?** No: see graphs below.
- **should the baseline be journal specific?**  The changing journal mix might be skewing baseline.  Hrm.  I'd rather not, because it would be nice to get "beyond the journal" and not do things that are journal specific, but in this case I think it is required.


h3.  Implementation and Results

Called like this
<pre>
  dat.research.norm = normalize_altmetrics(dat.research, altmetricsColumns)
</pre>

With this input data:

{{ d['sections']['do_normalization_idio.R|idio|rint|pyg']['get_research_articles'] }}

And these columns:

{{ d['sections']['do_normalization_idio.R|idio|rint|pyg']['altmetricsColumns'] }}


Results in this background data frame:

!file:///Users/hpiwowar/Documents/altmetrics.analysis/inst/doc_src/dexy_artifacts/mean_over_time_all.png!


Graphs of event-counts for research articles and the mean event counts within a 180 day window, by journal, over time

{% set num_mean_over_time_figures = 7 %}

{% for i in range(1,num_mean_over_time_figures+1) %}
{% set filename = ["mean_over_time_figure"]|join("") %}
<img src="file:///Users/hpiwowar/Documents/altmetrics.analysis/inst/doc_src/dexy_artifacts/mean_over_time_figure{{i}}.png" align="middle" alt="Mean over time, Figure {{i}}">
{% endfor %}

h2.  Transformation

After background-subtraction normalization, we do a transformation to make the data more normally distributed.


We are using this transformation:

{{ d['sections']['do_normalization_idio.R|idio|rint|pyg']['transformation'] }}


And it results in these distributions.

Note that in the diagrams below the ZEROs are not included because for some of the altmetrics they are so numerous it is hard to see anything else.

!file:///Users/hpiwowar/Documents/altmetrics.analysis/inst/doc_src/dexy_artifacts/altmetrics_distributions.png!



